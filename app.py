import streamlit as st
from pypdf import PdfReader
import re

# ==========================================
# 1. ç•Œé¢é…ç½®
# ==========================================
st.set_page_config(
    page_title="Scholar Flow RAG Multi", 
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS: ä¼˜åŒ–å¡ç‰‡æ ·å¼ï¼Œå¢åŠ æ–‡ä»¶åå­—æ®µçš„æ˜¾ç¤º
st.markdown("""
<style>
    .result-card {
        background-color: #f8fafc;
        padding: 15px;
        border-radius: 8px;
        border-left: 4px solid #3b82f6;
        margin-bottom: 15px;
        border: 1px solid #e2e8f0;
    }
    .meta-tag {
        background-color: #e0f2fe;
        color: #0369a1;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 0.8rem;
        font-weight: 600;
        margin-right: 10px;
        display: inline-block;
    }
    /* å¼ºåˆ¶æ¸²æŸ“æ•°å­¦å…¬å¼å­—ä½“ */
    .katex { font-size: 1.1em; }
</style>
""", unsafe_allow_html=True)

# ==========================================
# 2. æ ¸å¿ƒé€»è¾‘ (æ”¯æŒå¤šæ–‡ä»¶)
# ==========================================

@st.cache_data
def process_pdf(file):
    """è¯»å–å•ä¸ª PDF å¹¶æå–æ–‡æœ¬"""
    pages_data = []
    try:
        reader = PdfReader(file)
        for i, page in enumerate(reader.pages):
            text = page.extract_text()
            if text:
                # æ¸…æ´—ç©ºç™½å­—ç¬¦
                clean_text = re.sub(r'\s+', ' ', text).strip()
                # è®°å½•æ–‡ä»¶åã€é¡µç ã€æ–‡æœ¬
                pages_data.append({
                    "filename": file.name,
                    "page": i + 1, 
                    "text": clean_text
                })
    except Exception as e:
        st.error(f"è§£æ {file.name} å¤±è´¥: {e}")
    return pages_data

def search_engine(query, all_pages_data):
    results = []
    keywords = [k.lower() for k in query.split() if len(k) > 1]
    
    if not keywords: return []

    for data in all_pages_data:
        text = data['text']
        text_lower = text.lower()
        
        # è¯„åˆ†æœºåˆ¶
        score = 0
        for k in keywords:
            if k in text_lower:
                score += 1
        
        if score > 0:
            # æ™ºèƒ½æˆªå–ä¸Šä¸‹æ–‡
            first_idx = text_lower.find(keywords[0])
            start = max(0, first_idx - 150)
            end = min(len(text), first_idx + 350)
            
            snippet = text[start:end]
            if start > 0: snippet = "..." + snippet
            if end < len(text): snippet = snippet + "..."
            
            # é«˜äº®å¤„ç† (Markdown ç²—ä½“)
            for k in keywords:
                pattern = re.compile(re.escape(k), re.IGNORECASE)
                snippet = pattern.sub(lambda m: f"**{m.group(0)}**", snippet)

            results.append({
                "filename": data['filename'],
                "page": data['page'],
                "score": score,
                "snippet": snippet
            })
            
    # æŒ‰åˆ†æ•°æ’åº
    results.sort(key=lambda x: x['score'], reverse=True)
    return results[:8] # å¤šæ–‡ä»¶æ—¶è¿”å›æ›´å¤šç»“æœ

# ==========================================
# 3. ç•Œé¢å¸ƒå±€
# ==========================================

with st.sidebar:
    st.title("ğŸ“š çŸ¥è¯†åº“ (Library)")
    
    # === å…³é”®ä¿®æ”¹ï¼šaccept_multiple_files=True ===
    uploaded_files = st.file_uploader(
        "ä¸Šä¼  PDF (æ”¯æŒå¤šé€‰)", 
        type=['pdf'], 
        accept_multiple_files=True
    )
    
    knowledge_base = []
    
    if uploaded_files:
        with st.spinner(f"æ­£åœ¨åˆ†æ {len(uploaded_files)} ä¸ªæ–‡ä»¶..."):
            for file in uploaded_files:
                # å¾ªç¯å¤„ç†æ¯ä¸ªæ–‡ä»¶ï¼Œå¹¶å°†ç»“æœåˆå¹¶åˆ° knowledge_base
                file_pages = process_pdf(file)
                knowledge_base.extend(file_pages)
                
        st.success(f"âœ… å·²åŠ è½½ {len(uploaded_files)} ä¸ªæ–‡ä»¶\nå…± {len(knowledge_base)} é¡µç¬”è®°")
        
        # æ˜¾ç¤ºå·²åŠ è½½çš„æ–‡ä»¶åˆ—è¡¨
        with st.expander("å·²åŠ è½½æ–‡ä»¶åˆ—è¡¨"):
            for f in uploaded_files:
                st.text(f"â€¢ {f.name}")

st.title("ğŸ“ Scholar Flow Multi")
st.caption("æ”¯æŒå¤šæ–‡ä»¶æ£€ç´¢çš„ AI å­¦ä¹ åŠ©æ‰‹")

if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "assistant", "content": "ä½ å¥½ï¼è¯·ä¸€æ¬¡æ€§ä¸Šä¼ æ‰€æœ‰ç›¸å…³çš„ Lecture Notes æˆ–è€ƒå·ï¼Œæˆ‘ä¼šè·¨æ–‡ä»¶ä¸ºä½ å¯»æ‰¾ç­”æ¡ˆã€‚"}]

# æ˜¾ç¤ºå†å²
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        if "div class" in msg["content"]:
             st.markdown(msg["content"], unsafe_allow_html=True)
        else:
             st.write(msg["content"])

# è¾“å…¥æ¡†
if query := st.chat_input("è¾“å…¥é—®é¢˜ (ä¾‹å¦‚: definition of holomorphic)"):
    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.write(query)

    with st.chat_message("assistant"):
        if not knowledge_base:
            st.warning("âš ï¸ è¯·å…ˆåœ¨å·¦ä¾§ä¸Šä¼ è‡³å°‘ä¸€ä¸ª PDF æ–‡ä»¶ã€‚")
        else:
            results = search_engine(query, knowledge_base)
            
            if results:
                for res in results:
                    # æ˜¾ç¤ºæ–‡ä»¶å + é¡µç 
                    st.markdown(f"""
                    <div class="result-card">
                        <span class="meta-tag">ğŸ“„ {res['filename']}</span>
                        <span class="meta-tag">ç¬¬ {res['page']} é¡µ</span>
                        <div style="color: #334155; line-height: 1.6; margin-top:8px;">
                    """, unsafe_allow_html=True)
                    
                    st.markdown(res['snippet'])
                    
                    st.markdown("</div></div>", unsafe_allow_html=True)
                    
                st.session_state.messages.append({"role": "assistant", "content": "âœ… æœç´¢å®Œæˆ (è§ä¸Šæ–¹å¡ç‰‡)"})
            else:
                st.error("åœ¨æ‰€æœ‰æ–‡ä»¶ä¸­å‡æœªæ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
